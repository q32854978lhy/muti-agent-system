[env]
#时间限制(可以修改)
time_limit = 30
#每个时间步的长度(可以修改)
time_step = 0.2
val_size = 100
#测试的容量(可以修改)
test_size = 1000
#是否随机行人的大小和方向(可以修改)
randomize_attributes = true


[reward](谨慎修改)
success_reward = 1
collision_penalty = -0.25
discomfort_dist = 0.2
discomfort_penalty_factor = 0.5


[sim]
#测试的方法
train_val_sim = circle_crossing
test_sim = circle_crossing
square_width = 10
circle_radius = 4
#行人的个数(可以修改)
pedestrian_num = 5


[pedestrians]
#行人的参数
visible = true
method = orca
radius = 0.3
v_pref = 1
sensor = coordinates


[robot]
#机器人的参数
visible = false
method = none
radius = 0.3
v_pref = 1
sensor = coordinates


[rl]
#强化学习的参数
gamma = 0.9


[om]
cell_num = 4
cell_size = 1
om_channel_size = 3


[action_space]
#动作空间
kinematics = unicycle
speed_samples = 5(可以修改)
rotation_samples = 7(可以修改)
sampling = exponential
query_env = true


[cadrl](神经网络参数可以修改)
mlp_dims = 150, 100, 100, 1
multiagent_training = false


[lstm_rl](神经网络参数可以修改)
global_state_dim = 50
mlp1_dims = 150, 100, 100, 50
mlp2_dims = 150, 100, 100, 1
multiagent_training = true
with_om = false
with_interaction_module = true


[srl]
mlp1_dims = 150, 100, 100, 50
mlp2_dims = 150, 100, 100, 1
multiagent_training = true
with_om = false


[attention_rl](神经网络参数可以修改)
mlp1_dims = 150, 100
mlp2_dims = 100, 50
attention_dims = 100, 100, 1
mlp3_dims = 150, 100, 100, 1
multiagent_training = true
with_om = false(功能未完善)
with_global_state = false(功能未完善)

# 训练设置 

[trainer]
batch_size = 100


[imitation_learning]
imitationlearning_episodes = 3000
imitationlearning_method = orca
imitationlearning_epochs = 50
imitationlearning_learning_rate = 0.009
# 安全距离
safety_space = 0.15


[train]
reinforcementlearning_learning_rate = 0.0009
# 批次
train_batches = 100
# 训练片段次数(大概10000以上适宜,可以修改) 
train_episodes = 1000
# 每个片段的样本量
sample_episodes = 1
target_update_interval = 50
evaluation_interval = 1000
#样本的容量
capacity = 100000
epsilon_start = 0.5
epsilon_end = 0.1
epsilon_decay = 4000
checkpoint_interval = 1000